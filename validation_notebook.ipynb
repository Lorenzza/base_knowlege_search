{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация системы вопросов и ответов\n",
    "\n",
    "## Описание проекта\n",
    "\n",
    "Данный проект представляет собой систему вопросов и ответов, состоящую из трех микросервисов:\n",
    "\n",
    "1. **Search Service** (порт 8001)\n",
    "   - Использует модель SentenceTransformer для создания эмбеддингов\n",
    "   - Осуществляет семантический поиск по базе знаний\n",
    "   - Возвращает наиболее релевантные фрагменты текста\n",
    "\n",
    "2. **LLM Service** (порт 8002)\n",
    "   - Использует Mistral-7B для генерации ответов\n",
    "   - Принимает контекст из Search Service\n",
    "   - Генерирует структурированные ответы\n",
    "\n",
    "3. **Router Service** (порт 8003)\n",
    "   - Координирует взаимодействие между сервисами\n",
    "   - Обрабатывает входящие запросы\n",
    "   - Возвращает финальные ответы с метаданными\n",
    "\n",
    "## Архитектура решения\n",
    "\n",
    "```\n",
    "Client -> Router Service -> Search Service -> База знаний\n",
    "                        -> LLM Service    -> Генерация ответа\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Конфигурация\n",
    "ROUTER_URL = \"http://127.0.0.1:8003/ask\"\n",
    "SEARCH_URL = \"http://127.0.0.1:8001/search\"\n",
    "LLM_URL = \"http://127.0.0.1:8002/generate\"\n",
    "\n",
    "# Константы\n",
    "MAX_TOP_K = 5\n",
    "QUESTIONS = [\n",
    "    'Where can I apply Convolutional Neural Network?',\n",
    "    'What is Reinforcement Learning?',\n",
    "    'How to deploy a machine learning model?',\n",
    "    'How to implement a random forest algorithm?'\n",
    "]\n",
    "\n",
    "def send_question(question: str) -> Dict[str, Any]:\n",
    "    \"\"\"Отправка вопроса и получение ответа\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            ROUTER_URL,\n",
    "            json={\"question\": question},\n",
    "            timeout=360\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def search_documents(query: str, top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Поиск релевантных документов\n",
    "    \n",
    "    Args:\n",
    "        query (str): Поисковый запрос\n",
    "        top_k (int): Количество результатов (не более 5)\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: Список найденных документов\n",
    "    \"\"\"\n",
    "    # Ограничиваем top_k\n",
    "    top_k = min(max(1, top_k), MAX_TOP_K)\n",
    "    \n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": top_k\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Sending search request: {json.dumps(payload, indent=2)}\")\n",
    "        response = requests.post(SEARCH_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        results = response.json()\n",
    "        logger.info(f\"Found {len(results)} documents\")\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nSearch Results:\")\n",
    "        print(\"=\"*50)\n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"\\nDocument {i}:\")\n",
    "            print(f\"Title: {doc['title']}\")\n",
    "            print(f\"Score: {doc['score']:.4f}\")\n",
    "            print(f\"Content: {doc['content'][:200]}...\")\n",
    "        \n",
    "        # Вывод метрик\n",
    "        print(\"\\nSearch Metrics:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Response time: {response.elapsed.total_seconds():.2f} seconds\")\n",
    "        print(f\"Results found: {len(results)}\")\n",
    "        print(f\"Average relevance score: {sum(doc['score'] for doc in results)/len(results):.4f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search error: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция search_documents:**\n",
    "Функция search_documents:\r\n",
    "Ограничивает top_k до 5\r\n",
    "Выводит результаты поиска\r\n",
    "Показывает метрики поиска\r\n",
    "Возвращает результаты для дальнейшего использованияания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(question: str, context: List[Dict], max_context: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Отправка запроса к LLM\n",
    "    \n",
    "    Args:\n",
    "        question (str): Вопрос\n",
    "        context (List[Dict]): Контекст из поиска\n",
    "        max_context (int): Максимальное количество документов для контекста\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Ответ LLM\n",
    "    \"\"\"\n",
    "    # Ограничиваем количество документов\n",
    "    context = context[:min(len(context), max_context)]\n",
    "    \n",
    "    payload = {\n",
    "        \"question\": question,\n",
    "        \"context\": [\n",
    "            {\n",
    "                \"content\": doc[\"content\"],\n",
    "                \"title\": doc[\"title\"]\n",
    "            }\n",
    "            for doc in context\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Sending LLM request with {len(context)} documents\")\n",
    "        response = requests.post(LLM_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        # Вывод результата\n",
    "        print(\"\\nLLM Response:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"\\nMetrics:\")\n",
    "        print(f\"Model: {result['llm_name']}\")\n",
    "        print(f\"Latency: {result['latency']:.2f} seconds\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"LLM error: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Функция ask_llm:**\n",
    "\n",
    "Принимает результаты поиска\n",
    "Форматирует контекст для LLM\n",
    "Отправляет запрос\n",
    "Выводит ответ и метрики\n",
    "Возвращает полный ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 13:54:00,433 - INFO - Sending search request: {\n",
      "  \"query\": \"Where can I apply Convolutional Neural Network?\",\n",
      "  \"top_k\": 3\n",
      "}\n",
      "2024-11-05 13:54:00,471 - INFO - Found 3 documents\n",
      "2024-11-05 13:54:00,472 - INFO - Sending LLM request with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Title: Convolutional Neural Network: A Step By Step Guide\n",
      "Score: 0.6174\n",
      "Content: Convolutional Neural Network: A Step By Step Guide Shashikant · Follow Published in Towards Data Science · 9 min read · Mar 17, 2019 -- 1 Listen Share\n",
      "\n",
      "“Artificial Intelligence, deep learning, machine...\n",
      "\n",
      "Document 2:\n",
      "Title: An introduction to Convolutional Neural Networks\n",
      "Score: 0.5768\n",
      "Content: An introduction to Convolutional Neural Networks\n",
      "\n",
      "A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classific...\n",
      "\n",
      "Document 3:\n",
      "Title: Connectivity Patterns in Deep Neural Networks\n",
      "Score: 0.5729\n",
      "Content: This article will discuss a central component that is driving progress in Neural Network design, namely in Convolutional Networks for Computer Vision tasks. Classical CNNs such as LeNet-5, AlexNet, an...\n",
      "\n",
      "Search Metrics:\n",
      "==================================================\n",
      "Response time: 0.04 seconds\n",
      "Results found: 3\n",
      "Average relevance score: 0.5890\n",
      "\n",
      "LLM Response:\n",
      "==================================================\n",
      "Answer: Based on the context, Convolutional Neural Networks (CNNs) are primarily used for image processing, classification, and segmentation.\n",
      "\n",
      "Metrics:\n",
      "Model: TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n",
      "Latency: 26.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# Поиск ответа на вопрос 1 Where can I apply Convolutional Neural Network?:\n",
    "if __name__ == \"__main__\":\n",
    "    question = QUESTIONS[0]\n",
    "    \n",
    "    # Поиск документов\n",
    "    search_results = search_documents(question, top_k=3)\n",
    "    \n",
    "    # Запрос к LLM\n",
    "    llm_response = ask_llm(question, search_results, max_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 13:56:45,452 - INFO - Sending search request: {\n",
      "  \"query\": \"What is Reinforcement Learning?\",\n",
      "  \"top_k\": 3\n",
      "}\n",
      "2024-11-05 13:56:45,488 - INFO - Found 3 documents\n",
      "2024-11-05 13:56:45,490 - INFO - Sending LLM request with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Title: Reinforcement Learning : Markov-Decision Process (Part 1)\n",
      "Score: 0.7003\n",
      "Content:  Reinforcement Learning is all about goal to maximize the reward.So, let’s add reward to our Markov Chain.This gives us Markov Reward Process.\n",
      "\n",
      "Markov Reward Process : As the name suggests, MDPs are t...\n",
      "\n",
      "Document 2:\n",
      "Title: Simple Reinforcement Learning: Q-learning\n",
      "Score: 0.6977\n",
      "Content: Typical Exploring Image for RL - Credit @mike.shots\n",
      "\n",
      "Introduction\n",
      "\n",
      "One of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the...\n",
      "\n",
      "Document 3:\n",
      "Title: Teaching A Computer To Land On The Moon\n",
      "Score: 0.6802\n",
      "Content: ments. The program doing the learning and control is referred to as an agent.\n",
      "\n",
      "Agents that learn the correct approach to solving problems without being presented with lots of solved examples are doing...\n",
      "\n",
      "Search Metrics:\n",
      "==================================================\n",
      "Response time: 0.03 seconds\n",
      "Results found: 3\n",
      "Average relevance score: 0.6927\n",
      "\n",
      "LLM Response:\n",
      "==================================================\n",
      "Answer: Reinforcement Learning is a type of machine learning where an agent learns to make decisions by maximizing rewards in a given environment. This involves adding values or rewards to Markov Chains, which results in the Markov Reward Process (MDP). In this process, we get a value from every state our agent is in, and mathematically, it's defined as how much reward (Rs) we receive from a particular state S[t].\n",
      "\n",
      "Metrics:\n",
      "Model: TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n",
      "Latency: 35.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Поиск ответа на вопрос 2 What is Reinforcement Learning?:\n",
    "if __name__ == \"__main__\":\n",
    "    question = QUESTIONS[1]\n",
    "    \n",
    "    # Поиск документов\n",
    "    search_results = search_documents(question, top_k=3)\n",
    "    \n",
    "    # Запрос к LLM\n",
    "    llm_response = ask_llm(question, search_results, max_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 13:58:04,054 - INFO - Sending search request: {\n",
      "  \"query\": \"How to deploy a machine learning model?\",\n",
      "  \"top_k\": 3\n",
      "}\n",
      "2024-11-05 13:58:04,091 - INFO - Found 3 documents\n",
      "2024-11-05 13:58:04,091 - INFO - Sending LLM request with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Title: ML Models — Prototype to Production\n",
      "Score: 0.7547\n",
      "Content: significant challenge. As a data scientist and an ML practitioner, I have myself experienced that it is often more difficult to make the journey from a reliable and accurate prototype model to a well-...\n",
      "\n",
      "Document 2:\n",
      "Title: ML Models — Prototype to Production\n",
      "Score: 0.6834\n",
      "Content: of creating production machine learning services.\n",
      "\n",
      "The deployment and operational aspects of “productionizing” ML models lie at the intersection of various practices and disciplines like Statistical m...\n",
      "\n",
      "Document 3:\n",
      "Title: How Microsoft Azure Machine Learning Studio Clarifies Data Science\n",
      "Score: 0.6128\n",
      "Content: , Studio even makes deployment of models as a web service easy.\n",
      "\n",
      "But as I said in the title, Studio is not a panacea that allows anyone to build machine learning models. Machine learning is complex an...\n",
      "\n",
      "Search Metrics:\n",
      "==================================================\n",
      "Response time: 0.04 seconds\n",
      "Results found: 3\n",
      "Average relevance score: 0.6836\n",
      "\n",
      "LLM Response:\n",
      "==================================================\n",
      "Answer: Deploying a machine learning model involves more than just choosing a deployment stack. It also includes considerations for continuous improvement and deployment, security concerns, and performance optimization. These aspects fall at the intersection of various practices and disciplines like Statistical modeling, data science, DevOps, ML engineering, etc. Automating the build and deployment process is crucial to creating production machine learning services.\n",
      "\n",
      "Metrics:\n",
      "Model: TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n",
      "Latency: 29.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Поиск ответа на вопрос 3 How to deploy a machine learning model?:\n",
    "if __name__ == \"__main__\":\n",
    "    question = QUESTIONS[2]\n",
    "    \n",
    "    # Поиск документов\n",
    "    search_results = search_documents(question, top_k=3)\n",
    "    \n",
    "    # Запрос к LLM\n",
    "    llm_response = ask_llm(question, search_results, max_context=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 15:04:46,606 - INFO - Sending search request: {\n",
      "  \"query\": \"How to implement a random forest algorithm?\",\n",
      "  \"top_k\": 3\n",
      "}\n",
      "2024-11-05 15:04:46,645 - INFO - Found 3 documents\n",
      "2024-11-05 15:04:46,646 - INFO - Sending LLM request with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Title: Predict Employee Retention\n",
      "Score: 0.6459\n",
      "Content: represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition based on the attribute value. It partitions...\n",
      "\n",
      "Document 2:\n",
      "Title: Machine Learning Algorithms In Layman’s Terms, Part 2\n",
      "Score: 0.6449\n",
      "Content: o build little decision trees, each one of which is built simultaneously with random subsets of your data.\n",
      "\n",
      "…But There’s More!\n",
      "\n",
      "Not only does each tree in a Random Forest model only contain a subset o...\n",
      "\n",
      "Document 3:\n",
      "Title: Machine Learning Model Comparison for Breast Cancer Classification and Bio-Marker Identification\n",
      "Score: 0.6336\n",
      "Content:  forest model in hopes of achieving better accuracy and a more transparent machine model.\n",
      "\n",
      "This code builds a random search to identify the best parameters for the random forest to make its classifica...\n",
      "\n",
      "Search Metrics:\n",
      "==================================================\n",
      "Response time: 0.04 seconds\n",
      "Results found: 3\n",
      "Average relevance score: 0.6415\n",
      "\n",
      "LLM Response:\n",
      "==================================================\n",
      "Answer: To implement a Random Forest algorithm, follow these steps:\n",
      "        1. Preprocess the data by cleaning, transforming, and encoding features if necessary.\n",
      "        2. Split the dataset into training and testing sets.\n",
      "        3. Build multiple decision trees on randomly selected subsets of the data. For each tree:\n",
      "            a. Choose a random subset of features for splitting at each node.\n",
      "            b. Select the best split based on a criterion such as Gini impurity or entropy.\n",
      "            c. Repeat this process recursively until a stopping condition is met, like reaching a minimum number of samples per leaf node.\n",
      "        4. For new data points, get predictions from each tree in the forest and aggregate their results using voting (for classification) or averaging (for regression).\n",
      "\n",
      "Metrics:\n",
      "Model: TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n",
      "Latency: 46.28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Поиск ответа на вопрос 4 How to implement a random forest algorithm?:\n",
    "if __name__ == \"__main__\":\n",
    "    question = QUESTIONS[3]\n",
    "    \n",
    "    # Поиск документов\n",
    "    search_results = search_documents(question, top_k=3)\n",
    "    \n",
    "    # Запрос к LLM\n",
    "    llm_response = ask_llm(question, search_results, max_context=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе функции логируются и обрабатывают ошибки, выводят метрики производительности.\n",
    "Можно использовать их по отдельности или вместе, регулируя количество документов для поиска и контекста для LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Выводы\n",
    "\n",
    "1. **Качество ответов**:\n",
    "   Ответы релевантны запросам, но запросы носят очень общий характер и ответы подбираются соответственно. Можно улучшить выдачу, используя переформулировку вопросов.\n",
    "   Время обработки запросов - 0.03 - 0.04 секунды. Можно использовать Redis для скорости подгрузки информации.\n",
    "   В проекте в качестве метрики использовалась similarity, можно использовать дополнительные метрики, например, bm25. Также я хотела, но не успела попробовать другой вариант выбачи результатов (bi-encoder + cross-encoder).\n",
    "    Также можно расширенить базу знаний, чтобы иметь более профильные ответы.\n",
    "2. **Итоговый ответ LLM**:\n",
    "   Можно использовать в чат-ботах. В нашем валидационном ноутбуке видно, что ответ релевантен и базируется на полученном контексте из базы знаний, но расширен самой LLM. Это можно исправить, снижая температуру (сейчас 0.5) и подавая один самый релевантный ответ на вход в LLM. Ответ LLM пока выполняется долго, минимальное время - 22 секунды, на текущих вопросах - 26- 46 секунд.\n",
    "3. **Использование сервиса**\n",
    "   Сервис имеет документацию, папка DOCS с описанием.\n",
    "   \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
